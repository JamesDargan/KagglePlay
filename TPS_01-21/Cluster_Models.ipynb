{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.metrics import mean_squared_error, silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv', index_col='id')\n",
    "test = pd.read_csv('./data/test.csv', index_col='id')\n",
    "\n",
    "features = train.columns.drop('target')\n",
    "target = train.loc[:,['target']]\n",
    "train.drop(columns = ['target'], inplace = True)\n",
    "\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "train_ss = train.copy()\n",
    "train_ss = ss.fit_transform(train_ss)\n",
    "train_ss = pd.DataFrame(train_ss, index = train.index, columns = features)\n",
    "test_ss = test.copy()\n",
    "test_ss = ss.transform(test_ss)\n",
    "test_ss = pd.DataFrame(test_ss, index = test.index, columns = features)\n",
    "\n",
    "\n",
    "\n",
    "poly = PolynomialFeatures(degree = 2, include_bias=False)\n",
    "ss = StandardScaler()\n",
    "\n",
    "\n",
    "train_poly = train.copy()\n",
    "train_poly = poly.fit_transform(train_poly)\n",
    "train_poly = ss.fit_transform(train_poly)\n",
    "train_poly = pd.DataFrame(train_poly, index = train.index, columns = poly.get_feature_names(features))\n",
    "train_poly.columns = train_poly.columns.str.replace(' ', '_')\n",
    "\n",
    "test_poly = test.copy()\n",
    "test_poly = poly.transform(test_poly)\n",
    "test_poly = ss.transform(test_poly)\n",
    "test_poly = pd.DataFrame(test_poly, index = test.index, columns = poly.get_feature_names(features))\n",
    "test_poly.columns = test_poly.columns.str.replace(' ', '_')\n",
    "\n",
    "\n",
    "# Smaller Datasets for time efficient experimenting\n",
    "train_ss_sub = train_ss.sample(frac = 0.25, axis = 0, random_state = 42)\n",
    "train_ss_sub = train_ss_sub.sort_index()\n",
    "train_poly_sub = train_poly.loc[train_poly.index.isin(train_ss_sub.index),:]\n",
    "train_poly_sub = train_poly_sub.sort_index()\n",
    "target_sub = target.loc[target.index.isin(train_ss_sub.index), :]\n",
    "target_sub = target_sub.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_ss_sub,\n",
    "                                                    target_sub,\n",
    "                                                    test_size = 0.4,\n",
    "                                                    random_state = 42\n",
    "                                                   )\n",
    "X_train_poly, X_test_poly, y_train, y_test = train_test_split(train_poly_sub,\n",
    "                                                    target_sub,\n",
    "                                                    test_size = 0.4,\n",
    "                                                    random_state = 42\n",
    "                                                   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Cluster-Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>inertia</th>\n",
       "      <th>silhouette</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>439223.8537</td>\n",
       "      <td>0.2683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>384355.4894</td>\n",
       "      <td>0.1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>355524.1129</td>\n",
       "      <td>0.1872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>333715.6734</td>\n",
       "      <td>0.1502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>319824.8825</td>\n",
       "      <td>0.1416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>308185.9343</td>\n",
       "      <td>0.1346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>298675.3045</td>\n",
       "      <td>0.1345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>289811.1226</td>\n",
       "      <td>0.1177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>281841.6810</td>\n",
       "      <td>0.1152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>274564.8544</td>\n",
       "      <td>0.1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>269073.7697</td>\n",
       "      <td>0.1119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>263092.1832</td>\n",
       "      <td>0.1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>257755.0118</td>\n",
       "      <td>0.1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>252512.6774</td>\n",
       "      <td>0.1184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     k      inertia  silhouette\n",
       "0    2  439223.8537      0.2683\n",
       "1    3  384355.4894      0.1997\n",
       "2    4  355524.1129      0.1872\n",
       "3    5  333715.6734      0.1502\n",
       "4    6  319824.8825      0.1416\n",
       "5    7  308185.9343      0.1346\n",
       "6    8  298675.3045      0.1345\n",
       "7    9  289811.1226      0.1177\n",
       "8   10  281841.6810      0.1152\n",
       "9   11  274564.8544      0.1140\n",
       "10  12  269073.7697      0.1119\n",
       "11  13  263092.1832      0.1128\n",
       "12  14  257755.0118      0.1150\n",
       "13  15  252512.6774      0.1184"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_sil_scores_file = './summaries/sample_cluster_scores.csv'\n",
    "if not os.path.isfile(kmeans_sil_scores_file):\n",
    "    sil_scores = []\n",
    "    for k in range(2, 16):\n",
    "        km_cl = KMeans(n_clusters=k)\n",
    "        km_cl.fit(X_train)\n",
    "        inertia = km_cl.inertia_\n",
    "        sil = silhouette_score(X_train, km_cl.labels_)\n",
    "        sil_scores.append([k, inertia, sil])\n",
    "    sil_scores_df = pd.DataFrame(sil_scores)\n",
    "    sil_scores_df.columns = ['k', 'inertia', 'silhouette']\n",
    "    sil_scores_df.to_csv(kmeans_sil_scores_file, index = False)\n",
    "else:\n",
    "    sil_scores_df = pd.read_csv(kmeans_sil_scores_file, index_col = 'k')\n",
    "    \n",
    "round(sil_scores_df.head(15), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Average Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Average Train RMSE: 0.7281\n",
      "Cluster Average Test RMSE: 0.7264\n"
     ]
    }
   ],
   "source": [
    "km_clus = KMeans(n_clusters = 9, random_state = 42)\n",
    "km_clus.fit(X_train)\n",
    "\n",
    "y_clus = y_train.copy()\n",
    "y_clus['cluster'] = km_clus.labels_\n",
    "cluster_means = y_clus.groupby('cluster').mean().reset_index()\n",
    "cluster_means.columns = ['cluster', 'cl_mean']\n",
    "\n",
    "y_clus = y_clus.merge(cluster_means, how = 'left', on = 'cluster')\n",
    "clus_train_rmse = np.sqrt(mean_squared_error(y_clus['target'], y_clus['cl_mean']))\n",
    "print('Cluster Average Train RMSE: {:.4f}'.format(clus_train_rmse))\n",
    "\n",
    "\n",
    "y_hat_cluster = pd.DataFrame(km_clus.predict(X_test), index = X_test.index, columns = ['cluster'])\n",
    "y_hat_cluster = y_hat_cluster.merge(cluster_means, how = 'left', on = 'cluster')\n",
    "y_hat_cluster.index = X_test.index\n",
    "\n",
    "clus_test_rmse = np.sqrt(mean_squared_error(y_test, y_hat_cluster['cl_mean']))\n",
    "print('Cluster Average Test RMSE: {:.4f}'.format(clus_test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure Cluster Average Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Average Train RMSE: 0.7298\n"
     ]
    }
   ],
   "source": [
    "km_clus = KMeans(n_clusters = 9, random_state = 42)\n",
    "km_clus.fit(train_ss)\n",
    "\n",
    "y_clus = target.copy()\n",
    "y_clus['cluster'] = km_clus.labels_\n",
    "cluster_means = y_clus.groupby('cluster').mean().reset_index()\n",
    "cluster_means.columns = ['cluster', 'cl_mean']\n",
    "\n",
    "y_clus = y_clus.merge(cluster_means, how = 'left', on = 'cluster')\n",
    "clus_train_rmse = np.sqrt(mean_squared_error(y_clus['target'], y_clus['cl_mean']))\n",
    "print('Cluster Average Train RMSE: {:.4f}'.format(clus_train_rmse))\n",
    "\n",
    "\n",
    "y_sub_cluster = pd.DataFrame(km_clus.predict(test_ss), index = test_ss.index, columns = ['cluster'])\n",
    "y_sub_cluster = y_sub_cluster.merge(cluster_means, how = 'left', on = 'cluster')\n",
    "y_sub_cluster.index = test_ss.index\n",
    "y_sub_cluster = y_sub_cluster.drop('cluster', axis = 1)\n",
    "y_sub_cluster.columns = ['target']\n",
    "y_sub_cluster.to_csv('./submissions/cluster_sub.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanded Cluster Average Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Average Train RMSE: 0.7269\n"
     ]
    }
   ],
   "source": [
    "km_clus = KMeans(n_clusters = 20, random_state = 42)\n",
    "km_clus.fit(train_ss)\n",
    "\n",
    "y_clus = target.copy()\n",
    "y_clus['cluster'] = km_clus.labels_\n",
    "cluster_means = y_clus.groupby('cluster').mean().reset_index()\n",
    "cluster_means.columns = ['cluster', 'cl_mean']\n",
    "\n",
    "y_clus = y_clus.merge(cluster_means, how = 'left', on = 'cluster')\n",
    "clus_train_rmse = np.sqrt(mean_squared_error(y_clus['target'], y_clus['cl_mean']))\n",
    "print('Cluster Average Train RMSE: {:.4f}'.format(clus_train_rmse))\n",
    "\n",
    "\n",
    "y_sub_cluster = pd.DataFrame(km_clus.predict(test_ss), index = test_ss.index, columns = ['cluster'])\n",
    "y_sub_cluster = y_sub_cluster.merge(cluster_means, how = 'left', on = 'cluster')\n",
    "y_sub_cluster.index = test_ss.index\n",
    "y_sub_cluster = y_sub_cluster.drop('cluster', axis = 1)\n",
    "y_sub_cluster.columns = ['target']\n",
    "y_sub_cluster.to_csv('./submissions/cluster_sub2.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incorporate Cluster as OLS Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS with Poly Terms Test RMSE: 0.7167\n"
     ]
    }
   ],
   "source": [
    "ols_poly = LinearRegression()\n",
    "ols_poly.fit(X_train_poly, y_train)\n",
    "y_hat_ols_poly = ols_poly.predict(X_test_poly)\n",
    "rmse_ols_poly = np.sqrt(mean_squared_error(y_hat_ols_poly, y_test))\n",
    "\n",
    "print('OLS with Poly Terms Test RMSE: {:.4f}'.format(rmse_ols_poly))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS with Poly Terms and Clusters Test RMSE: 0.7168\n"
     ]
    }
   ],
   "source": [
    "km_clus = KMeans(n_clusters = 5, random_state = 42)\n",
    "km_clus.fit(X_train)\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(km_clus.labels_.reshape((len(km_clus.labels_),1)))\n",
    "clus_enc = enc.transform(km_clus.labels_.reshape((len(km_clus.labels_),1)))\n",
    "clus_ec_df = pd.DataFrame.sparse.from_spmatrix(clus_enc)\n",
    "clus_ec_df.columns = ['clus_' + str(c + 1) for c in clus_ec_df.columns ]\n",
    "clus_ec_df.index = X_train.index\n",
    "\n",
    "X_train_poly_clus = pd.merge(X_train_poly, clus_ec_df, left_index = True, right_index = True)\n",
    "X_train_poly_clus.drop(columns = ['clus_1'], inplace = True)\n",
    "\n",
    "\n",
    "clus_ec_test = enc.transform(km_clus.predict(X_test).reshape((X_test.shape[0],1)))\n",
    "clus_ec_test = pd.DataFrame.sparse.from_spmatrix(clus_ec_test)\n",
    "clus_ec_test.columns = ['clus_' + str(c + 1) for c in clus_ec_test.columns ]\n",
    "clus_ec_test.index = X_test.index\n",
    "\n",
    "X_test_poly_clus = pd.merge(X_test_poly, clus_ec_test, left_index = True, right_index = True)\n",
    "X_test_poly_clus.drop(columns = ['clus_1'], inplace = True)\n",
    "\n",
    "\n",
    "ols_poly_clus = LinearRegression()\n",
    "ols_poly_clus.fit(X_train_poly_clus, y_train)\n",
    "\n",
    "y_hat_ols_poly_clus = ols_poly_clus.predict(X_test_poly_clus)\n",
    "rmse_ols_poly_clus = np.sqrt(mean_squared_error(y_hat_ols_poly_clus, y_test))\n",
    "\n",
    "print('OLS with Poly Terms and Clusters Test RMSE: {:.4f}'.format(rmse_ols_poly_clus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS with Poly Terms and Clusters Test RMSE: 0.7164\n"
     ]
    }
   ],
   "source": [
    "km_clus = KMeans(n_clusters = 9, random_state = 42)\n",
    "km_clus.fit(X_train)\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(km_clus.labels_.reshape((len(km_clus.labels_),1)))\n",
    "clus_enc = enc.transform(km_clus.labels_.reshape((len(km_clus.labels_),1)))\n",
    "clus_ec_df = pd.DataFrame.sparse.from_spmatrix(clus_enc)\n",
    "clus_ec_df.columns = ['clus_' + str(c + 1) for c in clus_ec_df.columns ]\n",
    "clus_ec_df.index = X_train.index\n",
    "\n",
    "X_train_poly_clus = pd.merge(X_train_poly, clus_ec_df, left_index = True, right_index = True)\n",
    "X_train_poly_clus.drop(columns = ['clus_1'], inplace = True)\n",
    "\n",
    "\n",
    "clus_ec_test = enc.transform(km_clus.predict(X_test).reshape((X_test.shape[0],1)))\n",
    "clus_ec_test = pd.DataFrame.sparse.from_spmatrix(clus_ec_test)\n",
    "clus_ec_test.columns = ['clus_' + str(c + 1) for c in clus_ec_test.columns ]\n",
    "clus_ec_test.index = X_test.index\n",
    "\n",
    "X_test_poly_clus = pd.merge(X_test_poly, clus_ec_test, left_index = True, right_index = True)\n",
    "X_test_poly_clus.drop(columns = ['clus_1'], inplace = True)\n",
    "\n",
    "\n",
    "ols_poly_clus = LinearRegression()\n",
    "ols_poly_clus.fit(X_train_poly_clus, y_train)\n",
    "\n",
    "y_hat_ols_poly_clus = ols_poly_clus.predict(X_test_poly_clus)\n",
    "rmse_ols_poly_clus = np.sqrt(mean_squared_error(y_hat_ols_poly_clus, y_test))\n",
    "\n",
    "print('OLS with Poly Terms and Clusters Test RMSE: {:.4f}'.format(rmse_ols_poly_clus))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS with Poly Terms and Clusters Test RMSE: 0.7163\n"
     ]
    }
   ],
   "source": [
    "km_clus = KMeans(n_clusters = 20, random_state = 42)\n",
    "km_clus.fit(X_train)\n",
    "\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(km_clus.labels_.reshape((len(km_clus.labels_),1)))\n",
    "clus_enc = enc.transform(km_clus.labels_.reshape((len(km_clus.labels_),1)))\n",
    "clus_ec_df = pd.DataFrame.sparse.from_spmatrix(clus_enc)\n",
    "clus_ec_df.columns = ['clus_' + str(c + 1) for c in clus_ec_df.columns ]\n",
    "clus_ec_df.index = X_train.index\n",
    "\n",
    "X_train_poly_clus = pd.merge(X_train_poly, clus_ec_df, left_index = True, right_index = True)\n",
    "X_train_poly_clus.drop(columns = ['clus_1'], inplace = True)\n",
    "\n",
    "\n",
    "clus_ec_test = enc.transform(km_clus.predict(X_test).reshape((X_test.shape[0],1)))\n",
    "clus_ec_test = pd.DataFrame.sparse.from_spmatrix(clus_ec_test)\n",
    "clus_ec_test.columns = ['clus_' + str(c + 1) for c in clus_ec_test.columns ]\n",
    "clus_ec_test.index = X_test.index\n",
    "\n",
    "X_test_poly_clus = pd.merge(X_test_poly, clus_ec_test, left_index = True, right_index = True)\n",
    "X_test_poly_clus.drop(columns = ['clus_1'], inplace = True)\n",
    "\n",
    "\n",
    "ols_poly_clus = LinearRegression()\n",
    "ols_poly_clus.fit(X_train_poly_clus, y_train)\n",
    "\n",
    "y_hat_ols_poly_clus = ols_poly_clus.predict(X_test_poly_clus)\n",
    "rmse_ols_poly_clus = np.sqrt(mean_squared_error(y_hat_ols_poly_clus, y_test))\n",
    "\n",
    "print('OLS with Poly Terms and Clusters Test RMSE: {:.4f}'.format(rmse_ols_poly_clus))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS with Clusters Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_clus = KMeans(n_clusters = 9, random_state = 42)\n",
    "km_clus.fit(train_ss)\n",
    "\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(km_clus.labels_.reshape((len(km_clus.labels_),1)))\n",
    "clus_enc = enc.transform(km_clus.labels_.reshape((len(km_clus.labels_),1)))\n",
    "clus_ec_df = pd.DataFrame.sparse.from_spmatrix(clus_enc)\n",
    "clus_ec_df.columns = ['clus_' + str(c + 1) for c in clus_ec_df.columns ]\n",
    "clus_ec_df.index = train_ss.index\n",
    "\n",
    "X_train_poly_clus = pd.merge(train_poly, clus_ec_df, left_index = True, right_index = True)\n",
    "X_train_poly_clus.drop(columns = ['clus_1'], inplace = True)\n",
    "\n",
    "\n",
    "clus_ec_test = enc.transform(km_clus.predict(test_ss).reshape((test_ss.shape[0],1)))\n",
    "clus_ec_test = pd.DataFrame.sparse.from_spmatrix(clus_ec_test)\n",
    "clus_ec_test.columns = ['clus_' + str(c + 1) for c in clus_ec_test.columns ]\n",
    "clus_ec_test.index = test_ss.index\n",
    "\n",
    "X_test_poly_clus = pd.merge(test_poly, clus_ec_test, left_index = True, right_index = True)\n",
    "X_test_poly_clus.drop(columns = ['clus_1'], inplace = True)\n",
    "\n",
    "\n",
    "ols_poly_clus = LinearRegression()\n",
    "ols_poly_clus.fit(X_train_poly_clus, target)\n",
    "\n",
    "y_hat_ols_poly_clus = ols_poly_clus.predict(X_test_poly_clus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sub_ols_cl = pd.DataFrame(y_hat_ols_poly_clus)\n",
    "y_sub_ols_cl.index = test_ss.index\n",
    "y_sub_ols_cl.columns = ['target']\n",
    "y_sub_ols_cl.to_csv('./submissions/ols_cl9_sub.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed: 10.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30,\n",
       "                                           metric='minkowski',\n",
       "                                           metric_params=None, n_jobs=None,\n",
       "                                           n_neighbors=5, p=2,\n",
       "                                           weights='uniform'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'n_neighbors': range(11, 362, 50)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_params = {\n",
    "    'n_neighbors': range(11, 362, 50)\n",
    "}\n",
    "\n",
    "knn_gridsearcher = GridSearchCV(KNeighborsRegressor(), \n",
    "                                knn_params, \n",
    "                                scoring = 'neg_mean_squared_error', \n",
    "                                cv = 10, \n",
    "                                verbose = 1)\n",
    "knn_gridsearcher.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 111}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7158564465376754"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_knn = knn_gridsearcher.predict(X_test)\n",
    "\n",
    "print(knn_gridsearcher.best_params_)\n",
    "np.sqrt(mean_squared_error(y_test, yhat_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors = 111)\n",
    "knn.fit(train_ss, target)\n",
    "yhat_sub_knn = knn.predict(test_ss)\n",
    "\n",
    "yhat_sub_knn = pd.DataFrame(yhat_sub_knn)\n",
    "yhat_sub_knn.index = test_ss.index\n",
    "yhat_sub_knn.columns = ['target']\n",
    "yhat_sub_knn.to_csv('./submissions/knn111_sub.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
